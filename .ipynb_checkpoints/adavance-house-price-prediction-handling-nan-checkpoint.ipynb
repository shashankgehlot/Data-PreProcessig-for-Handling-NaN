{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import sys\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os \n",
    "dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "print()\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\", \"r\")\n",
    "print(f.read()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\n",
    "test_data=pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n",
    "frames = [test_data, train_data]\n",
    "data = pd.concat(frames)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking null values in Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2,figsize=(20,10),sharex=False,sharey=False)\n",
    "sns.heatmap(test_data.isnull(),ax=axs[0])\n",
    "sns.heatmap(train_data.isnull(),ax=axs[1])\n",
    "axs[0].set_title('test_data')\n",
    "axs[1].set_title('train_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking list of columns if it contains null value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns=data.columns[data.isnull().any()]\n",
    "null_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking counts of null value in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns=data.columns[data.isnull().any()]\n",
    "data[null_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating % of null value with respect to column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/2919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_with_nan_values=[feature for feature in data.columns if data[feature].isnull().sum()>=1]#\n",
    "#you can try \n",
    "#feature_with_nan_values= data.columns[data.isnull().any()]\n",
    "for feature in feature_with_nan_values:\n",
    "    print(feature,\"\",np.round(data[feature].isnull().mean(),5),\"% null values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking which row has null value\n",
    "#### in above code MSZoning has 4 null value ,what if we need to find which Rows contains null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"MSZoning\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitering out nullcolumns and rows where MSZoning is null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"MSZoning\"].isnull()][null_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter_null_dataframe contains only columns where data is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_null_dataframe=data[data.isnull().any(axis=1)][null_columns]\n",
    "filter_null_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types in Statistics\n",
    "### Categorical Data (Nominal, Ordinal)\n",
    "### Numerical Data (Discrete, Continuous, Interval, Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check which columns has numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "data.select_dtypes(include=[\"number\",\"bool\"]).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> check which column s has int and bool \"values\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include=[\"number\",\"bool\"]).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_string_values= data.select_dtypes(exclude=[\"number\",\"bool\"])\n",
    "data_with_string_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_int_values=data.select_dtypes(include=[\"number\",\"bool\"])\n",
    "data_with_int_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_string_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_string_values\n",
    "null_values=data_with_string_values.columns[data_with_string_values.isnull().any()]\n",
    "not_null_values=[item for item in data_with_string_values.columns if item not in null_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_string_values[null_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_string_values[not_null_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling NULL Values for Categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IN ML we can deal with null values in following ways\n",
    "* Delete  values : which Can cause huge loss of data\n",
    "* Assume Null values as new category\n",
    "* Imputation:- replace with most occuring\n",
    "* medianClassification by Ml algorithm    \n",
    "* Clustering by unsupervised learing technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_dataFrame=data_with_string_values[null_values]\n",
    "null_dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to check where nan values are less than 50 (means number of nan values are less then 50 ),We can impute NAN values in this columns with Most frequent Values in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_dataFrame.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_NaN_less_then_50=[feature for feature in null_dataFrame.columns if null_dataFrame[feature].isnull().sum()<50]\n",
    "columns_NaN_less_then_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_most_Frequent(DataFrame,ColumnName):\n",
    "    '''\n",
    "    1.) This function will replace NaN with Frequent ones\n",
    "    '''\n",
    "    print(DataFrame[ColumnName].isnull().sum(),\"null value present in\"+ColumnName)\n",
    "    column_index=DataFrame.columns.get_loc(ColumnName)\n",
    "    DataFrame.iloc[:,column_index] = DataFrame.iloc[:,column_index].fillna(DataFrame.iloc[:,column_index].value_counts().index[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['MSZoning',\n",
    " 'Utilities',\n",
    " 'Exterior1st',\n",
    " 'Exterior2nd',\n",
    " 'MasVnrType',\n",
    " 'Electrical',\n",
    " 'KitchenQual',\n",
    " 'Functional',\n",
    " 'SaleType'] are columns where nan values are less then  50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in columns_NaN_less_then_50:\n",
    "    print(\"processing column\",i)\n",
    "    replace_with_most_Frequent(null_dataFrame,i)\n",
    "\n",
    "null_dataFrame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Since Alley Column has more than 90% value NaN we can discard it, like wise Nan values in columns is more then 90% we can discard it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_NaN_is_more_then_90=[feature for feature in null_dataFrame.columns if (null_dataFrame[feature].isnull().sum()/null_dataFrame.shape[0])*100>90]\n",
    "columns_NaN_is_more_then_90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_column_from_dataframe(DataFrame,ColumnName):\n",
    "    '''\n",
    "      1)This Function deletes Column from DataFrame\n",
    "    '''\n",
    "    print((DataFrame[ColumnName].isnull().sum()/DataFrame.shape[0])*100,\" % null value present in function\")\n",
    "    del DataFrame[ColumnName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in columns_NaN_is_more_then_90:\n",
    "    print(\"processing column\",i)\n",
    "    delete_column_from_dataframe(null_dataFrame,i)\n",
    "null_dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets Assume where Null values are less than 250 we can Consider as a new categories (means we make null values as category \"UN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_NaN_less_then_250=[feature for feature in null_dataFrame.columns if (null_dataFrame[feature].isnull().sum()<250 and null_dataFrame[feature].isnull().sum()!=0)]\n",
    "columns_NaN_less_then_250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_dataFrame[columns_NaN_less_then_250].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  replace_nan_create_category(DataFrame,ColumnName):\n",
    "     '''\n",
    "      1)This Function makes Nan A new Category \n",
    "     '''\n",
    "     print(DataFrame[ColumnName].isnull().sum(),\"null value present in Columns\")\n",
    "     column_index=DataFrame.columns.get_loc(ColumnName)\n",
    "     DataFrame.iloc[:,column_index] = np.where(DataFrame.iloc[:,column_index].isnull(),\"UN\",DataFrame[ColumnName])\n",
    "     return DataFrame[ColumnName].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in columns_NaN_less_then_250:\n",
    "    print(\"processing column\",i)\n",
    "    replace_nan_create_category(null_dataFrame,i)\n",
    "null_dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have only two columns remaining with null data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"FireplaceQu\",\"Fence\"]:\n",
    "    print(i,null_dataFrame[i].isnull().sum()*100/null_dataFrame.shape[0],\"missing values\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
